#!/usr/bin/env python3
"""
Test suite for DC Energy Cost Forecasting System
Validates LightGBM implementation and target MAPE â‰¤ 5% accuracy
"""

import pytest
import pandas as pd
import numpy as np
import os
import sys
from datetime import datetime, timedelta

# Add project root to Python path
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from forecast.cost_engine import (
    cost_forecast,
    load_openinfra_telemetry,
    load_tariff_data,
    prepare_training_data,
    train_lightgbm_model,
    generate_power_forecast,
    calculate_cost_forecast,
    validate_forecast_accuracy,
    create_lag_features,
    resample_to_hourly
)

class TestDataPreparation:
    """Test data preparation and feature engineering functions."""
    
    def test_load_telemetry_data(self):
        """Test loading sample telemetry data."""
        telemetry_path = 'data/openinfra/sample_telemetry.csv'
        if os.path.exists(telemetry_path):
            df = load_openinfra_telemetry(telemetry_path)
            
            assert not df.empty, "Telemetry data should not be empty"
            assert 'timestamp' in df.columns, "Missing timestamp column"
            assert 'power_kw' in df.columns, "Missing power_kw column"
            assert 'device_id' in df.columns, "Missing device_id column"
            assert 'data_center' in df.columns, "Missing data_center column"
            
            # Check data types
            assert pd.api.types.is_datetime64_any_dtype(df['timestamp']), "Timestamp should be datetime"
            assert pd.api.types.is_numeric_dtype(df['power_kw']), "Power should be numeric"
    
    def test_load_tariff_data(self):
        """Test loading tariff data."""
        tariff_path = 'data/sample_tariff.csv'
        if os.path.exists(tariff_path):
            df = load_tariff_data(tariff_path)
            
            assert not df.empty, "Tariff data should not be empty"
            assert 'hour' in df.columns, "Missing hour column"
            assert 'rate_usd_per_kwh' in df.columns, "Missing rate column"
            assert 'demand_charge_usd_per_kw' in df.columns, "Missing demand charge column"
            
            # Check hour range
            assert df['hour'].min() >= 0, "Hour should be >= 0"
            assert df['hour'].max() <= 23, "Hour should be <= 23"
            
            # Check positive rates
            assert (df['rate_usd_per_kwh'] > 0).all(), "All rates should be positive"
    
    def test_resample_to_hourly(self):
        """Test resampling 5-minute data to hourly."""
        # Create sample 5-minute data
        timestamps = pd.date_range('2024-01-01', periods=24, freq='5T')
        sample_data = pd.DataFrame({
            'timestamp': timestamps,
            'power_kw': np.random.uniform(2.0, 4.0, len(timestamps)),
            'voltage_v': np.full(len(timestamps), 220),
            'current_a': np.random.uniform(10, 18, len(timestamps)),
            'device_id': ['server-001'] * len(timestamps),
            'data_center': ['dc-north'] * len(timestamps),
            'location': ['rack-a1'] * len(timestamps)
        })
        
        hourly_df = resample_to_hourly(sample_data)
        
        assert not hourly_df.empty, "Hourly resampling should not return empty DataFrame"
        assert len(hourly_df) == 2, "Should have 2 hours of data"  # 24 * 5min = 120min = 2 hours
        assert 'power_kw' in hourly_df.columns, "Should retain power_kw column"
    
    def test_create_lag_features(self):
        """Test lag feature creation."""
        # Create sample hourly data
        timestamps = pd.date_range('2024-01-01', periods=200, freq='1H')
        sample_data = pd.DataFrame({
            'power_kw': np.random.uniform(2.0, 4.0, len(timestamps))
        }, index=timestamps)
        
        featured_df = create_lag_features(sample_data)
        
        assert 'lag_1h' in featured_df.columns, "Should have lag_1h feature"
        assert 'lag_24h' in featured_df.columns, "Should have lag_24h feature"
        assert 'lag_168h' in featured_df.columns, "Should have lag_168h feature"
        assert 'hour_of_day' in featured_df.columns, "Should have hour_of_day feature"
        assert 'day_of_week' in featured_df.columns, "Should have day_of_week feature"
        assert 'rolling_mean_24h' in featured_df.columns, "Should have rolling mean"
        
        # Check feature ranges
        assert (featured_df['hour_of_day'] >= 0).all(), "Hour of day should be >= 0"
        assert (featured_df['hour_of_day'] <= 23).all(), "Hour of day should be <= 23"
        assert (featured_df['day_of_week'] >= 0).all(), "Day of week should be >= 0"
        assert (featured_df['day_of_week'] <= 6).all(), "Day of week should be <= 6"

class TestModelTraining:
    """Test LightGBM model training and validation."""
    
    def test_prepare_training_data(self):
        """Test training data preparation."""
        # Load real data if available
        telemetry_path = 'data/openinfra/sample_telemetry.csv'
        if os.path.exists(telemetry_path):
            df_telemetry = load_openinfra_telemetry(telemetry_path)
            
            if not df_telemetry.empty:
                prepared_data, feature_columns = prepare_training_data(df_telemetry)
                
                # Check feature columns
                expected_features = [
                    'lag_1h', 'lag_24h', 'lag_168h',
                    'hour_of_day', 'day_of_week', 'month', 'is_weekend',
                    'rolling_mean_24h', 'rolling_std_24h'
                ]
                
                for feature in expected_features:
                    assert feature in feature_columns, f"Missing feature: {feature}"
                
                if not prepared_data.empty:
                    assert 'power_kw' in prepared_data.columns, "Should have target column"
                    assert len(prepared_data.columns) >= len(feature_columns), "Should have all features"
    
    def test_model_training_pipeline(self):
        """Test complete model training pipeline."""
        telemetry_path = 'data/openinfra/sample_telemetry.csv'
        if os.path.exists(telemetry_path):
            df_telemetry = load_openinfra_telemetry(telemetry_path)
            
            if not df_telemetry.empty:
                prepared_data, feature_columns = prepare_training_data(df_telemetry)
                
                if len(prepared_data) > 50:  # Need sufficient data for training
                    try:
                        model = train_lightgbm_model(prepared_data, feature_columns)
                        assert model is not None, "Model training should succeed"
                        
                        # Test single prediction
                        test_features = prepared_data[feature_columns].iloc[-1:].values
                        prediction = model.predict(test_features)
                        
                        assert len(prediction) == 1, "Should get single prediction"
                        assert prediction[0] > 0, "Prediction should be positive"
                        
                    except Exception as e:
                        pytest.skip(f"Model training failed (expected with small dataset): {e}")

class TestCostForecasting:
    """Test complete cost forecasting functionality."""
    
    def test_cost_forecast_integration(self):
        """Test end-to-end cost forecasting."""
        telemetry_path = 'data/openinfra/sample_telemetry.csv'
        tariff_path = 'data/sample_tariff.csv'
        
        if os.path.exists(telemetry_path) and os.path.exists(tariff_path):
            df_usage = load_openinfra_telemetry(telemetry_path)
            df_tariff = load_tariff_data(tariff_path)
            
            if not df_usage.empty and not df_tariff.empty:
                forecast_df = cost_forecast(df_usage, df_tariff, horizon_h=6)
                
                if not forecast_df.empty:
                    # Check output columns
                    expected_cols = ['timestamp', 'predicted_power_kw', 'energy_cost_usd', 
                                   'demand_cost_usd', 'total_cost_usd']
                    
                    for col in expected_cols:
                        assert col in forecast_df.columns, f"Missing column: {col}"
                    
                    # Check data validity
                    assert (forecast_df['predicted_power_kw'] >= 0).all(), "Power should be non-negative"
                    assert (forecast_df['total_cost_usd'] >= 0).all(), "Cost should be non-negative"
                    assert len(forecast_df) == 6, "Should have 6 hours of forecast"
                    
                    # Check timestamp progression
                    time_diffs = forecast_df['timestamp'].diff().dropna()
                    expected_diff = pd.Timedelta(hours=1)
                    assert (time_diffs == expected_diff).all(), "Timestamps should be hourly"
    
    def test_cost_calculation(self):
        """Test cost calculation with known tariff rates."""
        # Create sample power forecast
        timestamps = pd.date_range('2024-01-01 12:00', periods=4, freq='1H')
        power_forecast = pd.DataFrame({
            'timestamp': timestamps,
            'predicted_power_kw': [10.0, 15.0, 8.0, 12.0]
        })
        
        # Create simple tariff
        tariff_data = pd.DataFrame({
            'hour': [12, 13, 14, 15],
            'rate_usd_per_kwh': [0.10, 0.15, 0.08, 0.12],
            'demand_charge_usd_per_kw': [10.0] * 4
        })
        
        cost_forecast = calculate_cost_forecast(power_forecast, tariff_data)
        
        assert not cost_forecast.empty, "Cost forecast should not be empty"
        assert len(cost_forecast) == 4, "Should have 4 cost predictions"
        
        # Check first hour calculation: 10 kW * $0.10 = $1.00 energy cost
        first_energy_cost = cost_forecast.iloc[0]['energy_cost_usd']
        assert abs(first_energy_cost - 1.0) < 0.01, f"Expected ~$1.00, got ${first_energy_cost:.2f}"
        
        # Check total cost includes demand charges
        first_total_cost = cost_forecast.iloc[0]['total_cost_usd']
        assert first_total_cost > first_energy_cost, "Total cost should include demand charges"

class TestModelValidation:
    """Test model validation and accuracy metrics."""
    
    def test_accuracy_validation(self):
        """Test forecast accuracy validation functions."""
        # Create sample actual vs predicted data
        timestamps = pd.date_range('2024-01-01', periods=24, freq='1H')
        
        actual_costs = pd.DataFrame({
            'timestamp': timestamps,
            'actual_cost': np.random.uniform(5.0, 15.0, 24)
        })
        
        # Create predictions with some error
        predicted_costs = pd.DataFrame({
            'timestamp': timestamps,
            'total_cost_usd': actual_costs['actual_cost'] * (1 + np.random.uniform(-0.05, 0.05, 24))
        })
        
        metrics = validate_forecast_accuracy(actual_costs, predicted_costs)
        
        assert 'mape_percent' in metrics, "Should have MAPE metric"
        assert 'rmse_usd' in metrics, "Should have RMSE metric"
        assert 'mae_usd' in metrics, "Should have MAE metric"
        assert 'samples' in metrics, "Should have sample count"
        
        assert metrics['mape_percent'] >= 0, "MAPE should be non-negative"
        assert metrics['rmse_usd'] >= 0, "RMSE should be non-negative"
        assert metrics['mae_usd'] >= 0, "MAE should be non-negative"
        assert metrics['samples'] == 24, "Should have 24 samples"

class TestAPIIntegration:
    """Test Flask API integration."""
    
    def test_intent_detection(self):
        """Test forecast intent detection."""
        from chat_api.routes import detect_forecast_intent
        
        # Test forecast queries
        forecast_queries = [
            "What will my energy costs be tomorrow?",
            "Predict power usage for next week",
            "Show me cost forecast for 24 hours",
            "How much will I spend on energy next day?"
        ]
        
        for query in forecast_queries:
            intent = detect_forecast_intent(query)
            assert intent['is_forecast'], f"Should detect forecast intent in: {query}"
            assert intent['horizon_h'] > 0, "Should have positive horizon"
        
        # Test non-forecast queries
        non_forecast_queries = [
            "Hello, how are you?",
            "What is a data center?",
            "Help me understand power systems"
        ]
        
        for query in non_forecast_queries:
            intent = detect_forecast_intent(query)
            assert not intent['is_forecast'], f"Should not detect forecast intent in: {query}"
    
    def test_response_formatting(self):
        """Test forecast response formatting."""
        from chat_api.routes import format_forecast_response
        
        # Create sample forecast data
        timestamps = pd.date_range('2024-01-01 12:00', periods=6, freq='1H')
        forecast_df = pd.DataFrame({
            'timestamp': timestamps,
            'predicted_power_kw': [10.0, 12.0, 8.0, 15.0, 11.0, 9.0],
            'total_cost_usd': [2.5, 3.0, 2.0, 4.0, 2.8, 2.2]
        })
        
        response = format_forecast_response(forecast_df, "What will costs be?")
        
        assert response['forecast_available'], "Should indicate forecast is available"
        assert 'response' in response, "Should have natural language response"
        assert 'summary' in response, "Should have summary statistics"
        
        summary = response['summary']
        assert 'total_cost_usd' in summary, "Should have total cost"
        assert 'avg_power_kw' in summary, "Should have average power"
        assert summary['forecast_hours'] == 6, "Should have correct horizon"

if __name__ == "__main__":
    pytest.main([__file__, "-v"]) 